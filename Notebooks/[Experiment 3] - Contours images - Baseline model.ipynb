{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "from skimage import measure\n",
    "from skimage import color\n",
    "from skimage.util import view_as_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail_contour(imgpath):\n",
    "    tail_img = skimage.io.imread(imgpath)\n",
    "    tail_img_gray = color.rgb2gray(tail_img)\n",
    "    max_gray = tail_img_gray.max()\n",
    "    min_gray = tail_img_gray.min()\n",
    "    # Apply a mask of 10% darkest grayscale of gray image\n",
    "    # There is no fixed threshold that fits all images\n",
    "    mask_threshold = min_gray + (max_gray - min_gray)  * 0.2\n",
    "    tail_img_mask = tail_img_gray < mask_threshold\n",
    "    contours = measure.find_contours(tail_img_mask, 0.9) \n",
    "    # Find the largest contour in the list of contours\n",
    "    largest_contour = contours[0]\n",
    "    largest_contour_size = contours[0].shape[0]\n",
    "    for c in contours:\n",
    "        if c.shape[0] > largest_contour_size:\n",
    "            largest_contour_size = c.shape[0]\n",
    "            largest_contour = c\n",
    "    return largest_contour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store all contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find contour from tail image, then store contour to output path\n",
    "#### Take only 1/2 bottom of contour image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_contour(source_img_path, output_path):\n",
    "    # Find contour from tail image\n",
    "    c = tail_contour(source_img_path)\n",
    "    # Move contour to line towards root (0,0)\n",
    "    c[:,0] -= c[:,0].min()\n",
    "    c[:,1] -= c[:,1].min()\n",
    "    # Cut the upper bottom of contour image\n",
    "    middle_y = (c[:,0].max() - c[:,0].min())/2\n",
    "    c_bottom = c[c[:,0] < middle_y]\n",
    "    \n",
    "    # Save image to output_path\n",
    "    fig = plt.figure(figsize=(8,3)) \n",
    "    plt.plot(c_bottom[:, 1], c_bottom[:, 0],  linewidth=1, color = 'black')  \n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, cmap = \"gray\", bbox_inches='tight')\n",
    "    plt.close(fig) # do not plot the image to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4715, 2)\n"
     ]
    }
   ],
   "source": [
    "# test with 1 file\n",
    "in_file = \"../data/test_val/PM-WWA-20170321-046.jpg\"\n",
    "out_file = \"../experiments/PM-WWA-20170321-046.jpg\"\n",
    "save_contour(in_file, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store test-val files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 50/808 images\n",
      "processed 100/808 images\n",
      "processed 150/808 images\n",
      "processed 200/808 images\n",
      "processed 250/808 images\n",
      "processed 300/808 images\n",
      "processed 350/808 images\n",
      "processed 400/808 images\n",
      "processed 450/808 images\n",
      "processed 500/808 images\n",
      "processed 550/808 images\n",
      "processed 600/808 images\n",
      "processed 650/808 images\n",
      "processed 700/808 images\n",
      "processed 750/808 images\n",
      "processed 800/808 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "testval_path = \"../data/test_val/\"\n",
    "testval_contour_path = \"../experiments/contour_mobilenet_0.2_bottom_half/test-val/\"\n",
    "\n",
    "images = os.listdir(testval_path)\n",
    "\n",
    "img_count = len(images)\n",
    "i = 0\n",
    "\n",
    "for img in images:\n",
    "    in_file = testval_path + img\n",
    "    out_file = testval_contour_path + img\n",
    "    save_contour(in_file, out_file)\n",
    "    \n",
    "    #progress tracking\n",
    "    i += 1\n",
    "    if (i%50 == 0):\n",
    "        print(\"processed {}/{} images\".format(i,img_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 50/4539 images (1.1%)\n",
      "processed 100/4539 images (2.2%)\n",
      "processed 150/4539 images (3.3%)\n",
      "processed 200/4539 images (4.41%)\n",
      "processed 250/4539 images (5.51%)\n",
      "processed 300/4539 images (6.61%)\n",
      "processed 350/4539 images (7.71%)\n",
      "processed 400/4539 images (8.81%)\n",
      "processed 450/4539 images (9.91%)\n",
      "processed 500/4539 images (11.02%)\n",
      "processed 550/4539 images (12.12%)\n",
      "processed 600/4539 images (13.22%)\n",
      "processed 650/4539 images (14.32%)\n",
      "processed 700/4539 images (15.42%)\n",
      "processed 750/4539 images (16.52%)\n",
      "processed 800/4539 images (17.63%)\n",
      "processed 850/4539 images (18.73%)\n",
      "processed 900/4539 images (19.83%)\n",
      "processed 950/4539 images (20.93%)\n",
      "processed 1000/4539 images (22.03%)\n",
      "processed 1050/4539 images (23.13%)\n",
      "processed 1100/4539 images (24.23%)\n",
      "processed 1150/4539 images (25.34%)\n",
      "processed 1200/4539 images (26.44%)\n",
      "processed 1250/4539 images (27.54%)\n",
      "processed 1300/4539 images (28.64%)\n",
      "processed 1350/4539 images (29.74%)\n",
      "processed 1400/4539 images (30.84%)\n",
      "processed 1450/4539 images (31.95%)\n",
      "processed 1500/4539 images (33.05%)\n",
      "processed 1550/4539 images (34.15%)\n",
      "processed 1600/4539 images (35.25%)\n",
      "processed 1650/4539 images (36.35%)\n",
      "processed 1700/4539 images (37.45%)\n",
      "processed 1750/4539 images (38.55%)\n",
      "processed 1800/4539 images (39.66%)\n",
      "processed 1850/4539 images (40.76%)\n",
      "processed 1900/4539 images (41.86%)\n",
      "processed 1950/4539 images (42.96%)\n",
      "processed 2000/4539 images (44.06%)\n",
      "processed 2050/4539 images (45.16%)\n",
      "processed 2100/4539 images (46.27%)\n",
      "processed 2150/4539 images (47.37%)\n",
      "processed 2200/4539 images (48.47%)\n",
      "processed 2250/4539 images (49.57%)\n",
      "processed 2300/4539 images (50.67%)\n",
      "processed 2350/4539 images (51.77%)\n",
      "processed 2400/4539 images (52.88%)\n",
      "processed 2450/4539 images (53.98%)\n",
      "processed 2500/4539 images (55.08%)\n",
      "processed 2550/4539 images (56.18%)\n",
      "processed 2600/4539 images (57.28%)\n",
      "processed 2650/4539 images (58.38%)\n",
      "processed 2700/4539 images (59.48%)\n",
      "processed 2750/4539 images (60.59%)\n",
      "processed 2800/4539 images (61.69%)\n",
      "processed 2850/4539 images (62.79%)\n",
      "processed 2900/4539 images (63.89%)\n",
      "processed 2950/4539 images (64.99%)\n",
      "processed 3000/4539 images (66.09%)\n",
      "processed 3050/4539 images (67.2%)\n",
      "processed 3100/4539 images (68.3%)\n",
      "processed 3150/4539 images (69.4%)\n",
      "processed 3200/4539 images (70.5%)\n",
      "processed 3250/4539 images (71.6%)\n",
      "processed 3300/4539 images (72.7%)\n",
      "processed 3350/4539 images (73.8%)\n",
      "processed 3400/4539 images (74.91%)\n",
      "processed 3450/4539 images (76.01%)\n",
      "processed 3500/4539 images (77.11%)\n",
      "processed 3550/4539 images (78.21%)\n",
      "processed 3600/4539 images (79.31%)\n",
      "processed 3650/4539 images (80.41%)\n",
      "processed 3700/4539 images (81.52%)\n",
      "processed 3750/4539 images (82.62%)\n",
      "processed 3800/4539 images (83.72%)\n",
      "processed 3850/4539 images (84.82%)\n",
      "processed 3900/4539 images (85.92%)\n",
      "processed 3950/4539 images (87.02%)\n",
      "processed 4000/4539 images (88.13%)\n",
      "processed 4050/4539 images (89.23%)\n",
      "processed 4100/4539 images (90.33%)\n",
      "processed 4150/4539 images (91.43%)\n",
      "processed 4200/4539 images (92.53%)\n",
      "processed 4250/4539 images (93.63%)\n",
      "processed 4300/4539 images (94.73%)\n",
      "processed 4350/4539 images (95.84%)\n",
      "processed 4400/4539 images (96.94%)\n",
      "processed 4450/4539 images (98.04%)\n",
      "processed 4500/4539 images (99.14%)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../data/train/\"\n",
    "train_contour_path = \"../experiments/contour_mobilenet_0.2_bottom_half/train/\"\n",
    "\n",
    "subfolders = os.listdir(train_path)\n",
    "\n",
    "train_file_count = 4539 # We know in advance the number of training images\n",
    "i=0\n",
    "\n",
    "for sf in subfolders:\n",
    "    # Create sub-folder for train contours if not exist\n",
    "    train_contour_path_subfolder = train_contour_path + sf\n",
    "    if not os.path.exists(train_contour_path_subfolder):\n",
    "        os.makedirs(train_contour_path_subfolder)  \n",
    "    \n",
    "    # Get list of images in each subfolder\n",
    "    images = os.listdir(train_path + sf)\n",
    "    # Find contour for each image\n",
    "    for img in images:\n",
    "        in_file = train_path + sf + \"/\" + img\n",
    "        out_file = train_contour_path + sf + \"/\" + img\n",
    "        save_contour(in_file, out_file)\n",
    "        #progress tracking\n",
    "        i += 1\n",
    "        if (i%50 == 0):\n",
    "            print(\"processed {}/{} images ({}%)\".format(i,train_file_count,round(i/train_file_count*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
